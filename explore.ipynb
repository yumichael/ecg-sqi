{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# hello world\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "notebook_rc = dict(mpl.rcParams)\n",
    "# mpl.rcParams.update(notebook_rc)\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import cufflinks as cf\n",
    "\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "from pytil.utility import *\n",
    "from pytil.attributes import attribute_accessor as AA\n",
    "from pytil.object import Namespace as Ob\n",
    "from pytil.quickvis import canvas\n",
    "#canvas(12.3, 12.3)\n",
    "\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "import scipy.linalg as linalg\n",
    "from time import time\n",
    "\n",
    "from pathlib import Path\n",
    "data_dir = Path('./cinc2011/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "tls.warnings.warn = lambda *args, **kwargs: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Signal Quality of ECG sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**As a heads up**,  \n",
    "you may need to refresh the page any time you come across a slide that includes an interactive plot,\n",
    "because limited RAM causes the plot to not immediately load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "def get_tar_data(url):\n",
    "    file_loc = data_dir / url.split('/')[-1]\n",
    "    r = requests.get(url)\n",
    "    with file_loc.open('wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "    tarfile.open(str(file_loc)).extractall(str(data_dir))\n",
    "    return\n",
    "#get_tar_data('https://physionet.org/physiobank/database/challenge/2011/set-a.tar.gz')\n",
    "#get_tar_data('https://physionet.org/physiobank/database/challenge/2011/set-b.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_dimensions(a, lo, hi):\n",
    "   return a.reshape(a.shape[:lo] + (prod(a.shape[lo:hi+1]),) + a.shape[hi+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = data_dir / 'set-a'\n",
    "idents_list = []\n",
    "for suffix in '', '-acceptable', '-unacceptable':\n",
    "    _name = 'RECORDS' + suffix\n",
    "    with (train_dir / _name).open('r') as f:\n",
    "        idents_list.append([int(x) for x in f.readlines()])\n",
    "[ident_all, ident_good, ident_bad] = [sp.asarray(idents) for idents in idents_list]\n",
    "orig_tables = {}\n",
    "for i in ident_all:\n",
    "    orig_tables[i] = pd.read_csv(train_dir / '{}.txt'.format(i), header=None, usecols=range(1, 13))\n",
    "    orig_tables[i].columns = 'I II III aVR aVL aVF V1 V2 V3 V4 V5 V6'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The 12-lead ECG\n",
    "\n",
    "|<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c9/Limb_leads.svg\" width=\"300\" />|<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/41/Precordial_leads_in_ECG.png\" width=\"200\" />|\n",
    "|---|---|\n",
    "|<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/19/Limb_leads_of_EKG.png\" width=\"300\" />|<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/0e/EKG_leads.png\" width=\"200\" />|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "[**PhysioNet/Computing in Cardiology Challenge 2011**](https://physionet.org/challenge/2011/)\n",
    "\n",
    "#### Training Set A\n",
    "1000 counts of 10 second long 12-lead ECG records.  \n",
    "Acceptable/unacceptable quality labels available\n",
    "\n",
    "#### Training Set B\n",
    "500 counts of 10 second long 12-lead ECG records.  \n",
    "Quality labels not publicly available.  \n",
    "** *not used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def _normalize(table):\n",
    "    table_min, table_max = table.min(), table.max()\n",
    "    table_range = table_max - table_min\n",
    "    return (table - table_min) / (sp.where(table_range == 0, 1, table_range))\n",
    "norm_tables = dictmap(_normalize, orig_tables)\n",
    "def _downsample(table):\n",
    "    s = (table.index.to_series() / 5).astype(table.index.dtype)\n",
    "    return table.groupby(s).mean()\n",
    "downsamp_tables = dictmap(_downsample, norm_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "thetables = norm_tables\n",
    "def add_subplot(fig, df, row, col):\n",
    "    for column in df.columns:\n",
    "        fig.append_trace({'x': df.index, 'y': df[column], 'name': column}, row, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Normalized signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = tls.make_subplots(rows=1, cols=2, subplot_titles=('Good', 'Bad'), shared_yaxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#add_subplot(fig, norm_tables[ident_good[43]] + list(range(11, -1, -1)), 1, 1)\n",
    "#add_subplot(fig, norm_tables[ident_bad[132]] + list(range(11, -1, -1)), 1, 2)\n",
    "#py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Downsampled normalized signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = tls.make_subplots(rows=1, cols=2, subplot_titles=('Good', 'Bad'), shared_yaxes=True)\n",
    "add_subplot(fig, downsamp_tables[ident_good[43]] + list(range(11, -1, -1)), 1, 1)\n",
    "add_subplot(fig, downsamp_tables[ident_bad[132]] + list(range(11, -1, -1)), 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~michaely/360.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Please refresh the page if you do not see a data visualization plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def _variation(table):\n",
    "    return table.diff().abs().sum()\n",
    "variation_tables = dictmap(_variation, norm_tables)\n",
    "variations_good = sp.stack(variation_tables[i].as_matrix() for i in ident_good)\n",
    "variations_bad = sp.stack(variation_tables[i].as_matrix() for i in ident_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "layout = go.Layout(title=\"Histogram of variations of ECG records\", xaxis=dict(title='variation in record'), barmode='overlay')\n",
    "_v = [sp.log(v.min(axis=1) + 1) for v in (variations_good, variations_bad)]\n",
    "data = [go.Histogram(x=_v[0], name='good', nbinsx=30, opacity=0.55), go.Histogram(x=_v[1], name='bad', nbinsx=30, opacity=0.55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~michaely/350.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(go.Figure(data=data, layout=layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Please refresh the page if you do not see a data visualization plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs of good records with a flat signal (0 variation) in one lead:  [1968453 2080991 2151032 2536401 2537839 2883516]\n",
      "The number of good records with no flat signals:  767\n",
      "The number of bad records with no flat signals:  96\n"
     ]
    }
   ],
   "source": [
    "ident_good_missing = ident_good[sp.where((variations_good == 0).sum(axis=1) == 1)[0]]\n",
    "print('IDs of good records with a flat signal (0 variation) in one lead: ', ident_good_missing)\n",
    "ident_good_complete = ident_good[sp.where((variations_good == 0).sum(axis=1) == 0)[0]]\n",
    "print('The number of good records with no flat signals: ', len(ident_good_complete))\n",
    "ident_bad_complete = ident_bad[sp.where((variations_bad == 0).sum(axis=1) == 0)[0]]\n",
    "print('The number of bad records with no flat signals: ', len(ident_bad_complete))\n",
    "ident_all_complete = sp.concatenate([ident_good_complete, ident_bad_complete])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### References\n",
    "**Dimensionality reduction: A comparative review**  \n",
    "LJP Van der Maaten, EO Postma, HJ Van den Herik  \n",
    "(2009) Technical Report TiCC TR 2009-005\n",
    "\n",
    "**Common manifold learning using alternating-diffusion**  \n",
    "RR Lederman, R Talmon  \n",
    "(2014) Yale University, New Haven, CT, USA, Tech. Rep. YALEU/DCS/TR-1497\n",
    "\n",
    "**Out-of-sample extensions for lle, isomap, mds, eigenmaps, and spectral clustering**  \n",
    "Y Bengio, JF Paiement, P Vincent, O Delalleau, N Le Roux, M Ouimet  \n",
    "(2004) Advances in neural information processing systems 16, 177-184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goal\n",
    "Create a Signal Quality Index for short window intervals of ECG signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method:**\n",
    "- Keep only records where all signals are not flat\n",
    "- Partition data into training set and validation set (50/50, evenly splitting good and bad)\n",
    "- Take Fourier transforms of 40 samples of 0.8-second windows from 431 training records $\\Longrightarrow X\\supset X_0$\n",
    "- Nonlinearly reduce dimensionality of samples (expect ECGs to follow a low dimensional pattern)\n",
    " - Perform custom alternating Laplacian eigenmap $\\Longrightarrow X_0\\stackrel{\\text{LEM}}\\to Y_0$\n",
    "- Use extension algorithm to describe how to map unseen data in the same nonlinear way $\\Longrightarrow X\\stackrel{\\text{LEM}'}\\to Y$\n",
    "- Take another sample batch from the training set and train a classifier after reducing dimensions\n",
    "  $\\Longrightarrow X_1\\stackrel{\\text{LEM}'}\\to Y_1\\stackrel{\\text{train}}{\\leftrightarrow}\\text{labels}$\n",
    "- Test the pipeline with samples from the validation set $\\Longrightarrow X_{\\text{test}}\\stackrel{\\text{LEM}'}\\to Y_{\\text{test}}\\stackrel{\\text{eval}}{\\leftrightarrow}\\text{labels}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "theident_all = ident_all_complete\n",
    "theident_good = ident_good_complete\n",
    "theident_bad = ident_bad_complete\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "skf = StratifiedShuffleSplit(n_splits=1, test_size=0.5)\n",
    "_label = sp.in1d(theident_all, theident_bad)\n",
    "_train, _validation = skf.split(theident_all, _label).__next__()\n",
    "ident_train = theident_all[_train]\n",
    "label_train = _label[_train]\n",
    "ident_validation = theident_all[_validation]\n",
    "label_validation = _label[_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import rfft\n",
    "def rolling_window(x, window, axis):\n",
    "    if axis < 0:\n",
    "        axis += len(x.shape)\n",
    "    shape = x.shape[:axis] + (x.shape[axis] - window + 1, window) + x.shape[axis + 1:]\n",
    "    strides = x.strides[:axis] + (x.strides[axis],) + x.strides[axis:]\n",
    "    return as_strided(x, shape=shape, strides=strides)\n",
    "thetables = downsamp_tables\n",
    "n_samples = 40\n",
    "sample_length = 80\n",
    "def sample_record(i):\n",
    "    matrix = thetables[i].as_matrix()\n",
    "    samples_idx = sp.random.permutation(matrix.shape[0] - sample_length + 1)[:n_samples]\n",
    "    windows = rolling_window(matrix, sample_length, 0)\n",
    "    freq = rfft(windows[samples_idx], axis=1)[:, 1:, :]\n",
    "    return freq, samples_idx\n",
    "def create_samples(ident):\n",
    "    sr = [sample_record(i) for i in ident]\n",
    "    sample_windows = sp.stack([a[0] for a in sr])\n",
    "    sample_indices = sp.stack([a[1] for a in sr])\n",
    "    return sample_windows, sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2757.3036420345306"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symscale = lambda M, x: x[:, sp.newaxis] * M * x\n",
    "alpha = .5\n",
    "nnn = 120\n",
    "\n",
    "t0 = time()\n",
    "sample_windows0, sample_indices0 = create_samples(ident_train)\n",
    "XX0 = flatten_dimensions(sample_windows0, 0, 1)\n",
    "X_0 = flatten_dimensions(XX0, 1, 2)\n",
    "l0 = sp.concatenate([lbl * sp.ones(n_samples) for lbl in label_train])\n",
    "\n",
    "W0 = sp.zeros((len(XX0), len(XX0)))\n",
    "sigma0_alt = [None for i in range(12)]\n",
    "d0_alt = [None for i in range(12)]\n",
    "for lead in range(12):\n",
    "    _X = XX0[..., lead]\n",
    "    _E = squareform(pdist(_X, 'sqeuclidean'))\n",
    "    sigma0_alt[lead] = sp.sqrt(sp.sort(_E, axis=0)[nnn])\n",
    "    _W = sp.exp(-symscale(_E, 1 / (sigma0_alt[lead] + 0.00001)))\n",
    "    _d = _W.sum(axis=1)\n",
    "    # alpha normalization\n",
    "    _W = symscale(_W, _d ** -alpha)\n",
    "    # make transition matrix\n",
    "    d0_alt[lead] = _W.sum(axis=1)\n",
    "    W0 += (1 / d0_alt[lead])[:, sp.newaxis] * _W\n",
    "d0 = W0.sum(axis=0)\n",
    "A0 = (1 / d0)[:, sp.newaxis] * W0\n",
    "\n",
    "# find eigenvectors of diffusion transition matrix\n",
    "mu, U = sp.linalg.eig(A0)\n",
    "# eigh puts eigenvalues in ascending order, but we want descending order\n",
    "order = sp.argsort(-mu)\n",
    "mu = mu[order]\n",
    "U = U.T[order].T\n",
    "ev = sp.real(mu[:200])\n",
    "Y0 = sp.real(U[:, :200])\n",
    "\n",
    "t1 = time()\n",
    "t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    sp.savez(\n",
    "        \"samp40nnn800x.npz\",\n",
    "        sigma0_alt=sigma0_alt,\n",
    "        d0_alt=d0_alt,\n",
    "        mu=mu,\n",
    "        ev=ev,\n",
    "        Y0=Y0,\n",
    "        Y=Y,\n",
    "        Y_test=Y_test,\n",
    "        sample_windows0 = sample_windows0,\n",
    "        sample_indices0 = sample_windows0,\n",
    "        sample_windows = sample_windows,\n",
    "        sample_indices = sample_windows,\n",
    "        sample_windows_test = sample_windows_test,\n",
    "        sample_indices_test = sample_windows_test\n",
    "    )\n",
    "#save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualization via Laplacian Eigenmap\n",
    "\n",
    "Please refresh the page after pressing down arrow if the 3D plot is not showing up!  \n",
    "The diagram takes a lot of computing power so refreshing makes the page successfully display the current plot instead of previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "sset = sp.random.permutation(Y0.shape[0])[:8000]\n",
    "marker = dict(size='2', color=label_train*1, showscale=True, colorscale='Jet', opacity=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~michaely/332.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [go.Scatter3d(x=Y0[sset, 1], y=Y0[sset, 2], z=Y0[sset, 3], mode='markers', marker=marker)]\n",
    "py.iplot(go.Figure(data=data, layout=go.Layout(title=\"Laplacian Eigenmap for X0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Please refresh the page if you do not see a data visualization plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313.9706711769104"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time()\n",
    "n_samples = 20\n",
    "sample_windows, sample_indices = create_samples(ident_train)\n",
    "XX = flatten_dimensions(sample_windows, 0, 1)\n",
    "X_ = flatten_dimensions(XX, 1, 2)\n",
    "l = sp.concatenate([lbl * sp.ones(n_samples) for lbl in label_train])\n",
    "\n",
    "def y(XX):\n",
    "    W = sp.zeros((len(XX), len(XX0)))\n",
    "    for lead in range(12):\n",
    "        _X0 = XX0[..., lead]\n",
    "        _X = XX[..., lead]\n",
    "        _E = cdist(_X, _X0, 'sqeuclidean')\n",
    "        _sigma = sp.sqrt(sp.sort(_E, axis=1)[:, nnn])\n",
    "        _W = sp.exp(-(1 / (_sigma + 0.00001))[:, sp.newaxis] * _E * (1 / (sigma0_alt[lead] + 0.00001)))\n",
    "        _d = _W.sum(axis=1)\n",
    "        _W = (_d ** -alpha)[:, sp.newaxis] * _W * (d0_alt[lead] ** -alpha)\n",
    "        _d = _W.sum(axis=1)\n",
    "        W += (1 / _d)[:, sp.newaxis] * _W\n",
    "    d = W.sum(axis=1)\n",
    "    A = (1 / d)[:, sp.newaxis] * W\n",
    "    return sp.real(A @ Y0 / ev)\n",
    "Y = y(XX)\n",
    "\n",
    "t1 = time()\n",
    "t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = tls.make_subplots(rows=1, cols=2, subplot_titles=('X0', 'X1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~michaely/330.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [go.Scatter3d(x=Y[sset, 1], y=Y[sset, 2], z=Y[sset, 3], mode='markers', marker=marker)]\n",
    "py.iplot(go.Figure(data=data, layout=go.Layout(title=\"Laplacian Eigenmap for X1\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Please refresh the page if you do not see a data visualization plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~michaely/194.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ev).iplot(title=\"Eigenvalues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Please refresh the page if you do not see a data visualization plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "sample_windows_test, sample_indices_test = create_samples(ident_validation)\n",
    "XX_test = flatten_dimensions(sample_windows_test, 0, 1)\n",
    "X_test = flatten_dimensions(XX_test, 1, 2)\n",
    "l_test = sp.concatenate([lbl * sp.ones(n_samples) for lbl in label_validation])\n",
    "Y_test = y(XX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierEvaluation():\n",
    "    def __init__(self, classifier, fit, predict, y_transform=identity):\n",
    "        self.classifier = classifier\n",
    "        self.fit_method = fit\n",
    "        self.predict_method = predict\n",
    "        self.y_transform = y_transform\n",
    "    def fit(self, X, y):\n",
    "        return self.fit_method(self.classifier)(X, y)\n",
    "    def test(self, X, y):\n",
    "        self.predicted = self.y_transform(self.predict_method(self.classifier)(X))\n",
    "        info = (self.predicted >= 0.5) - y\n",
    "        self.error = (info == -1).sum(), (info == 1).sum()\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "xgb = ClassifierEvaluation(XGBClassifier(), AA.fit, AA.predict)\n",
    "logistic = ClassifierEvaluation(LogisticRegression(), AA.fit, AA.decision_function, lambda y: 1 / (1 + sp.exp(-y)))\n",
    "knn = ClassifierEvaluation(KNeighborsClassifier(n_neighbors=3), AA.fit, AA.predict)\n",
    "models = dict(xgb=xgb, logistic=logistic, knn=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def test_lem(model_names):\n",
    "    for name in model_names:\n",
    "        models[name].fit(Y, l)\n",
    "        models[name].test(Y_test, l_test)\n",
    "def test_raw(model_names):\n",
    "    for name in model_names:\n",
    "        models[name].fit(sp.concatenate([X_0, X_]), sp.concatenate([l0, l]))\n",
    "        models[name].test(X_test, l_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Not very good actually...\n",
    "\n",
    "Running the classifiers even without dimension reduction actually arguably do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "label = label_validation\n",
    "n = n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples:  8640\n",
      "samples per class (good, bad): (7680, 960)\n",
      "raw model errors: Logistic = (953, 23) , XGBoost = (722, 30)\n",
      "stacking models on eigenmap results: Logistic = (960, 0) , XGBoost = (592, 156)\n"
     ]
    }
   ],
   "source": [
    "print(\"total samples: \", len(label)*n)\n",
    "print(\"samples per class (good, bad):\", (sum(label == 0) * n, sum(label == 1) * n))\n",
    "test_raw(['logistic', 'xgb'])\n",
    "print(\"raw model errors: Logistic =\", models['logistic'].error, \", XGBoost =\", models['xgb'].error)\n",
    "test_lem(['logistic', 'xgb'])\n",
    "print(\"stacking models on eigenmap results: Logistic =\", models['logistic'].error, \", XGBoost =\", models['xgb'].error)\n",
    "# kNN tends to be very bad, so we'll skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But, we see that one thing the dimensionality reduction did for us is that it has a perfect (by available data) ability to recognize when a ECG snippet is from a bad quality one (from the logistic regression model). This means the dimensionality reduction has fully extracted the variation across the data which all bad quality signals have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640 7680 960\n",
      "raw (638, 257) (803, 143)\n",
      "lem (676, 233) (960, 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "/print len(ident_validation)*n_samples sum(label_validation==0)*n_samples sum(label_validation==1)*n_samples\n",
    "test_raw()\n",
    "/print \"raw\" models['xgb'].error models['logistic'].error\n",
    "test_lem()\n",
    "/print \"lem\" models['xgb'].error models['logistic'].error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "sqi = model.predicted.reshape(sample_indices_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266.2426674365997"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(3, perplexity=30)\n",
    "t0 = time()\n",
    "fitted = tsne.fit_transform(XX0.reshape((XX0.shape[0], XX0.shape[1] * XX0.shape[2])))\n",
    "t1 = time()\n",
    "t1 - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bonus t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~michaely/358.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot([go.Scatter3d(x=fitted[sset, 0], y=fitted[sset, 1], z=fitted[sset, 2], mode='markers', marker=marker)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Please refresh the page if you do not see a data visualization plot_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Data science is a difficult art. Real data does not so easily fall to the nice mathematical techniques that work wonders on simulated data (which we _a priori_ understand fully anyway, having been generated by us). I experimented with applying the nonlinear dimensionality reduction before running supervised learning not in order to focus on improving classification, but rather to learn about the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### random stuff"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
